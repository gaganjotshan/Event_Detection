{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzsPXp_oXulk"
   },
   "source": [
    "# New section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92yUGwgIqeA2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CLASSPATH'] = \"/content/drive/MyDrive/Event_Extraction/stanford/stanford-postagger-2017-06-09\"\n",
    "os.environ[\"STANFORD_MODELS\"] = \"/content/drive/MyDrive/Event_Extraction/stanford/stanford-postagger-2017-06-09/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1653317774800,
     "user": {
      "displayName": "Gaganjot Shan",
      "userId": "18300755219130239353"
     },
     "user_tz": -120
    },
    "id": "nRt8Hj2eYeLI",
    "outputId": "5464b669-f064-4b3c-9593-badaa9b6f92f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.parse import CoreNLPParser\n",
    "from nltk.tag import StanfordPOSTagger\n",
    "from nltk.tokenize.stanford import StanfordTokenizer\n",
    "from nltk.tokenize.stanford_segmenter import StanfordSegmenter\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1653317774801,
     "user": {
      "displayName": "Gaganjot Shan",
      "userId": "18300755219130239353"
     },
     "user_tz": -120
    },
    "id": "FyUxK6tN-pUl",
    "outputId": "076b2974-5fca-4fb1-ff7a-9a9741d5bbd2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nltk.parse.corenlp.CoreNLPDependencyParser"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nltk.parse.CoreNLPParser\n",
    "nltk.parse.CoreNLPDependencyParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DPoDUmdiYnG7"
   },
   "outputs": [],
   "source": [
    "trainFile = '/content/drive/MyDrive/Event_Extraction/Corpus/SemEval2010_task8_training/TRAIN_FILE.TXT'\n",
    "testFile = '/content/drive/MyDrive/Event_Extraction/Corpus/SemEval2010_task8_testing_keys/TEST_FILE_FULL.TXT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MW5UWbQjY-aV"
   },
   "outputs": [],
   "source": [
    "op_trainFile = \"/content/drive/MyDrive/Event_Extraction/files/train_attn.txt\"\n",
    "op_testFile = \"/content/drive/MyDrive/Event_Extraction/files/test_attn.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARo3QSOe83qD"
   },
   "source": [
    "import warnings\n",
    "# Raise deprecation warning. \n",
    "warnings.simplefilter(\"always\", DeprecationWarning) \n",
    "warnings.warn( \n",
    "    str( \n",
    "        \"\\nThe StanfordTokenizer will \" \n",
    "        \"be deprecated in version 3.2.5.\\n\" \n",
    "        \"Please use \\033[91mnltk.parse.corenlp.CoreNLPTokenizer\\033[0m instead.'\" \n",
    "        ), \n",
    "        DeprecationWarning, \n",
    "        stacklevel=2, \n",
    "        ) \n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56FOvuAS9KsA"
   },
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxDiGKbFkCY6"
   },
   "outputs": [],
   "source": [
    "stanford_dir = \"/content/drive/MyDrive/Event_Extraction/stanford\"\n",
    "modelfile = stanford_dir+\"/stanford-postagger-2017-06-09/models/english-bidirectional-distsim.tagger.props\"\n",
    "jarfile = stanford_dir+\"/stanford-postagger-2017-06-09/stanford-postagger.jar\"\n",
    "tagger = StanfordPOSTagger(model_filename= modelfile, path_to_jar=jarfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVSj2AGFmSqc"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "#verbPOS = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEbfwB6vB6Te"
   },
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUIAS6IptMLf"
   },
   "outputs": [],
   "source": [
    "from nltk import parse\n",
    "def createFile(filepath, outputpath):    \n",
    "    \n",
    "    def clean_tokens(sent_num, tokens):\n",
    "        ret = []\n",
    "        for t in tokens:\n",
    "            t = t.strip().split() #remove whitespaces and breaks up a string at the specified separator and returns a list of strings.\n",
    "            if len(t) > 1: \n",
    "                print(sent_num, t)\n",
    "            t = \" \".join(t)\n",
    "            ret.append(t)\n",
    "        return ret \n",
    "    \n",
    "    fOut = open(outputpath, 'w')\n",
    "    lines = [line.strip() for line in open(filepath)]\n",
    "    for idx in range(0, len(lines), 4):\n",
    "        sentence_num = lines[idx].split(\"\\t\")[0]\n",
    "        sentence = lines[idx].split(\"\\t\")[1][1:-1]\n",
    "        label = lines[idx+1]\n",
    "        \n",
    "        sentence = sentence.replace(\"<e1>\", \" E1_START \").replace(\"</e1>\", \" E1_END \")\n",
    "        sentence = sentence.replace(\"<e2>\", \" E2_START \").replace(\"</e2>\", \" E2_END \")\n",
    "\n",
    "        #tokenization and converting tokens to lowerCase\n",
    "        #tokens = nltk.sent_tokenize(sentence)\n",
    "\n",
    "        tokens = StanfordTokenizer().tokenize(sentence)   \n",
    "        #'tokens'.lower()     \n",
    "        tokens = clean_tokens(sentence_num, [t.lower() for t in tokens])\n",
    "        #tokensPOS = tagger.tag(tokens)\n",
    "        tokensPOS = nltk.pos_tag(tokens)\n",
    "\n",
    "        fOut.write(\" \".join([ label, \" \".join(tokens) ]))\n",
    "        fOut.write(\"\\n\")\n",
    "    fOut.close()\n",
    "        \n",
    "    print(outputpath, \"created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3792310,
     "status": "ok",
     "timestamp": 1653321567105,
     "user": {
      "displayName": "Gaganjot Shan",
      "userId": "18300755219130239353"
     },
     "user_tz": -120
    },
    "id": "WqjtXJ4Ttrrm",
    "outputId": "fa776fa3-4456-45d8-f183-4aa8374d15da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2609 ['1', '1/2']\n",
      "7589 ['1', '1/2']\n",
      "/content/drive/MyDrive/Event_Extraction/files/train_attn.txt created\n",
      "10591 ['1', '1/4']\n",
      "10665 ['6', '1/2']\n",
      "/content/drive/MyDrive/Event_Extraction/files/test_attn.txt created\n",
      "Train / Test file created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "createFile(trainFile, op_trainFile)\n",
    "\n",
    "createFile(testFile, op_testFile)\n",
    "\n",
    "print(\"Train / Test file created\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPff/jAxgB3OO0M269m6iCB",
   "collapsed_sections": [],
   "mount_file_id": "1SjtW_kLU9-KZTZhs46cMZM6g8SXKfcaS",
   "name": "trainingset_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
