{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5109,
     "status": "ok",
     "timestamp": 1654540218733,
     "user": {
      "displayName": "Gaganjot Shan",
      "userId": "18300755219130239353"
     },
     "user_tz": -120
    },
    "id": "9B32JiKJWp1y",
    "outputId": "ae62ee83-6fe2-44ee-b959-b98a506327f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting keras==2.8\n",
      "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Installing collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.9.0\n",
      "    Uninstalling keras-2.9.0:\n",
      "      Successfully uninstalled keras-2.9.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.8.2+zzzcolab20220527125636 requires tensorboard<2.9,>=2.8, but you have tensorboard 1.15.0 which is incompatible.\n",
      "tensorflow 2.8.2+zzzcolab20220527125636 requires tensorflow-estimator<2.9,>=2.8, but you have tensorflow-estimator 1.15.1 which is incompatible.\n",
      "tensorflow-cpu 2.9.1 requires keras<2.10.0,>=2.9.0rc0, but you have keras 2.8.0 which is incompatible.\n",
      "tensorflow-cpu 2.9.1 requires tensorboard<2.10,>=2.9, but you have tensorboard 1.15.0 which is incompatible.\n",
      "tensorflow-cpu 2.9.1 requires tensorflow-estimator<2.10.0,>=2.9.0rc0, but you have tensorflow-estimator 1.15.1 which is incompatible.\u001b[0m\n",
      "Successfully installed keras-2.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install keras==2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3201,
     "status": "ok",
     "timestamp": 1654540221930,
     "user": {
      "displayName": "Gaganjot Shan",
      "userId": "18300755219130239353"
     },
     "user_tz": -120
    },
    "id": "8RNK8tDbXyBQ",
    "outputId": "732b7b1b-ea38-483b-e2fd-7d6fd8daaedf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: api in /usr/local/lib/python3.7/dist-packages (0.0.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from api) (2.23.0)\n",
      "Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from api) (1.3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->api) (2022.5.18.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->api) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->api) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->api) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2524,
     "status": "ok",
     "timestamp": 1654540224449,
     "user": {
      "displayName": "Gaganjot Shan",
      "userId": "18300755219130239353"
     },
     "user_tz": -120
    },
    "id": "eJZcdHw-vMcN",
    "outputId": "7ef37ce4-0827-4712-c874-e148281b4487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: keras_vggface in /usr/local/lib/python3.7/dist-packages (0.6)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras_vggface) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras_vggface) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_vggface) (1.21.6)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras_vggface) (2.8.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras_vggface) (1.15.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from keras_vggface) (7.1.2)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_vggface) (3.1.0)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras_vggface) (1.5.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_vggface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1654540224449,
     "user": {
      "displayName": "Gaganjot Shan",
      "userId": "18300755219130239353"
     },
     "user_tz": -120
    },
    "id": "v9Yfb7WJMQwo"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1654540224450,
     "user": {
      "displayName": "Gaganjot Shan",
      "userId": "18300755219130239353"
     },
     "user_tz": -120
    },
    "id": "oSrHYAI0MS8N"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow-gpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2806,
     "status": "ok",
     "timestamp": 1654540227252,
     "user": {
      "displayName": "Gaganjot Shan",
      "userId": "18300755219130239353"
     },
     "user_tz": -120
    },
    "id": "CtVeGyEj0Bvr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337) \n",
    "import os \n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Concatenate, Embedding, Input, Dropout, Dense, Activation, Bidirectional, GlobalMaxPooling1D\n",
    "from keras.layers import Convolution1D, LSTM, GRU, CuDNNGRU, CuDNNLSTM, Permute, Lambda, Flatten\n",
    "from keras import optimizers\n",
    "#from keras.engine.topology import Layer\n",
    "#from keras.utils.layer_utils import Layer\n",
    "#from keras import layers\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from keras import regularizers\n",
    "from keras.models import load_model\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1907,
     "status": "ok",
     "timestamp": 1654540229155,
     "user": {
      "displayName": "Gaganjot Shan",
      "userId": "18300755219130239353"
     },
     "user_tz": -120
    },
    "id": "pJeIvF2vDpZd",
    "outputId": "e1de69d0-83e0-454b-dc9d-ffbe5db53b81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1654540229155,
     "user": {
      "displayName": "Gaganjot Shan",
      "userId": "18300755219130239353"
     },
     "user_tz": -120
    },
    "id": "QgI9x5eN0xor"
   },
   "outputs": [],
   "source": [
    "data_npy_path = \"/Users/shan/Desktop/Event_Extraction/data/data_all.npy\"\n",
    "scorer_perl_script = \"/content/drive/MyDrive/Event_Extraction/Corpus/SemEval2010_task8_scorer-v1.2/semeval2010_task8_scorer-v1.2.pl\"\n",
    "train_answer_keys = '/content/drive/MyDrive/Event_Extraction/files/train_answer_keys.txt'\n",
    "val_answer_keys = '/content/drive/MyDrive/Event_Extraction/files/val_answer_keys.txt'\n",
    "test_answer_keys = '/content/drive/MyDrive/Event_Extraction/files//test_answer_keys.txt'\n",
    "\n",
    "proposed_ans = \"/content/drive/MyDrive/Event_Extraction/model/proposed_ans.txt\"\n",
    "scorer_output = \"/content/drive/MyDrive/Event_Extraction/model/scorer_output.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1654540229155,
     "user": {
      "displayName": "Gaganjot Shan",
      "userId": "18300755219130239353"
     },
     "user_tz": -120
    },
    "id": "HIp-wcpc2ENJ",
    "outputId": "b398a558-2f00-4980-c721-c099f41a4671"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape (7208, 101)\n",
      "train_y.shape (7208,)\n",
      "val_x.shape (792, 101)\n",
      "val_y.shape (792,)\n",
      "test_x.shape (2717, 101)\n",
      "test_y.shape (2717,)\n",
      "embedding.shape (23450, 300)\n",
      "len(label_to_int) 19\n",
      "len(int_to_label) 19\n",
      "max_sentence_len 101\n",
      "n_out 19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data Loading\n",
    "from keras.datasets import imdb\n",
    "\n",
    "# save np.load\n",
    "# modify the default parameters of np.load\n",
    "np.load.__defaults__=(None, True, True, 'ASCII')\n",
    "\n",
    "# call load_data with allow_pickle implicitly set to true\n",
    "\n",
    "train_set, val_set, test_set, embedding, label_to_int, int_to_label =  np.load(data_npy_path)\n",
    "# restore np.load for future normal usage\n",
    "\n",
    "\n",
    "train_x, train_y = train_set\n",
    "val_x, val_y = val_set\n",
    "test_x, test_y = test_set\n",
    "\n",
    "train_x_copy = train_x\n",
    "train_y_copy = train_y\n",
    "\n",
    "max_sentence_len = train_x.shape[1]\n",
    "n_out = len(label_to_int)\n",
    "\n",
    "print(\"train_x.shape\", train_x.shape)\n",
    "print(\"train_y.shape\", train_y.shape)\n",
    "print(\"val_x.shape\", val_x.shape)\n",
    "print(\"val_y.shape\", val_y.shape)\n",
    "print(\"test_x.shape\", test_x.shape)\n",
    "print(\"test_y.shape\", test_y.shape)\n",
    "print(\"embedding.shape\", embedding.shape)\n",
    "print(\"len(label_to_int)\", len(label_to_int))\n",
    "print(\"len(int_to_label)\", len(int_to_label))\n",
    "print(\"max_sentence_len\", max_sentence_len)\n",
    "print(\"n_out\", n_out)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1654540229156,
     "user": {
      "displayName": "Gaganjot Shan",
      "userId": "18300755219130239353"
     },
     "user_tz": -120
    },
    "id": "QUoxWc1OZH93"
   },
   "outputs": [],
   "source": [
    "def get_mask_entities(x):\n",
    "    ''' 1 for entity words, 0 otherwise '''\n",
    "    \n",
    "    ret = np.zeros_like(x)\n",
    "    #print(\"get_mask shape\", ret.shape)\n",
    "    # e1s 2409\n",
    "    # e1e 2408\n",
    "    # e2s 2411\n",
    "    # e2e 2410\n",
    "    for i in range(x.shape[0]): \n",
    "        e1 = [0, 0]\n",
    "        e2 = [0, 0]\n",
    "        for j in range(x.shape[1]):\n",
    "            if x[i][j] == 2409:\n",
    "                e1[0] = j\n",
    "            elif x[i][j] == 2408: \n",
    "                e1[1] = j\n",
    "            elif x[i][j] == 2411: \n",
    "                e2[0] = j\n",
    "            elif x[i][j] == 2410: \n",
    "                e2[1] = j\n",
    "                break\n",
    "        for j in range(e1[0]+1, e1[1]): \n",
    "            ret[i][j] = 1\n",
    "        for j in range(e2[0]+1, e2[1]): \n",
    "            ret[i][j] = 1\n",
    "        #print(ret[i][e1[0]:e1[1]+1], x[i][e1[0]:e1[1]+1])\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12599,
     "status": "ok",
     "timestamp": 1654540241751,
     "user": {
      "displayName": "Gaganjot Shan",
      "userId": "18300755219130239353"
     },
     "user_tz": -120
    },
    "id": "0w7Xil-uZLZX",
    "outputId": "05b11200-cfa2-4e33-8243-c36e1dfd297b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x_mask.shape (7208, 101)\n",
      "train_x_mask_copy.shape (7208, 101)\n",
      "val_x_mask.shape (792, 101)\n",
      "test_x_mask.shape (2717, 101)\n"
     ]
    }
   ],
   "source": [
    "train_x_mask = get_mask_entities(train_x)\n",
    "train_x_mask_copy = train_x_mask\n",
    "val_x_mask = get_mask_entities(val_x)\n",
    "test_x_mask = get_mask_entities(test_x)\n",
    "\n",
    "print(\"train_x_mask.shape\", train_x_mask.shape)\n",
    "print(\"train_x_mask_copy.shape\", train_x_mask_copy.shape)\n",
    "print(\"val_x_mask.shape\", val_x_mask.shape)\n",
    "print(\"test_x_mask.shape\", test_x_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1654540241752,
     "user": {
      "displayName": "Gaganjot Shan",
      "userId": "18300755219130239353"
     },
     "user_tz": -120
    },
    "id": "uUoCPxdYZcPn",
    "outputId": "f4643793-5395-4cb9-d2f8-b01e82fc6308"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "units 64\n",
      "batch_size 128\n",
      "dropout_emb 0.64\n",
      "dropout_model 0.32\n",
      "dropout_pen 0.32\n",
      "l2_val 1e-05\n",
      "learning_rate 1.0\n",
      "activation_fn tanh\n",
      "nb_epoch 256\n",
      "adadelta <keras.optimizer_v2.adadelta.Adadelta object at 0x7f65f6627310>\n",
      "save_model True\n",
      "es_epoch_stop 20\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adadelta.py:74: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adadelta, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Parameters \n",
    "\n",
    "units = 64\n",
    "batch_size = 128 #10\n",
    "dropout_emb = 0.64\n",
    "dropout_model = 0.32\n",
    "dropout_pen = 0.32\n",
    "l2_val = 0.00001\n",
    "learning_rate = 1.0\n",
    "activation_fn = 'tanh'\n",
    "nb_epoch = 256\n",
    "adadelta = tf.optimizers.Adadelta(lr=learning_rate, decay=0.0)\n",
    "save_model = True\n",
    "es_epoch_stop = 20\n",
    "\n",
    "print(\"units\", units)\n",
    "print(\"batch_size\", batch_size)\n",
    "print(\"dropout_emb\", dropout_emb)\n",
    "print(\"dropout_model\", dropout_model)\n",
    "print(\"dropout_pen\", dropout_pen)\n",
    "print(\"l2_val\", l2_val)\n",
    "print(\"learning_rate\", learning_rate)\n",
    "print(\"activation_fn\", activation_fn)\n",
    "print(\"nb_epoch\", nb_epoch)\n",
    "print(\"adadelta\", adadelta)\n",
    "print(\"save_model\", save_model)\n",
    "print(\"es_epoch_stop\", es_epoch_stop)\n",
    "print()\n",
    "\n",
    "embeddings_reg = regularizers.l2(l2_val)\n",
    "kernel_reg = regularizers.l2(l2_val)\n",
    "recurrent_reg = regularizers.l2(l2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1654540241752,
     "user": {
      "displayName": "Gaganjot Shan",
      "userId": "18300755219130239353"
     },
     "user_tz": -120
    },
    "id": "Ba5gou34ZwQz"
   },
   "outputs": [],
   "source": [
    "class MaskMaxPoolingLayer(Layer):\n",
    "    # input_shape [(None, 101, 600), (None, 101)]\n",
    "    # input:  (?, 101, 600) (?, 101)\n",
    "    # output: (?, 600)\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super(MaskMaxPoolingLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(MaskMaxPoolingLayer, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, x):\n",
    "        x_1_float32 = K.cast(x[1], dtype='float32')\n",
    "        #print(\"x_1_float32\", x_1_float32)\n",
    "        x_0 = K.permute_dimensions(x[0], pattern=[2, 0, 1])\n",
    "        #print(\"x_0\", x_0)\n",
    "        x_0 = tf.multiply(x_0, x_1_float32)\n",
    "        #print(\"x_0\", x_0)\n",
    "        x_0 = K.permute_dimensions(x_0, pattern=[1, 2, 0])\n",
    "        #print(\"x_0\", x_0)\n",
    "        x_0 = K.max(x_0, axis=-2)\n",
    "        #print(\"x_0\", x_0)\n",
    "        return x_0\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # input_shape [(None, 101, 600), (None, 101)]\n",
    "        return (input_shape[0][0], input_shape[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 987,
     "status": "ok",
     "timestamp": 1654540242718,
     "user": {
      "displayName": "Gaganjot Shan",
      "userId": "18300755219130239353"
     },
     "user_tz": -120
    },
    "id": "a6qIV3Nkp7Da",
    "outputId": "52d5397a-64d9-432d-96d9-d19f0ead3f49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method MaskMaxPoolingLayer.call of <__main__.MaskMaxPoolingLayer object at 0x7f65f3c504d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method MaskMaxPoolingLayer.call of <__main__.MaskMaxPoolingLayer object at 0x7f65f3c504d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Model: \"model\"\n",
      "________________________________________________________________________________________________________________________\n",
      " Layer (type)                          Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      " words_input (InputLayer)              [(None, 101)]              0             []                                      \n",
      "                                                                                                                        \n",
      " words_Embedding (Embedding)           (None, 101, 300)           7035000       ['words_input[0][0]']                   \n",
      "                                                                                                                        \n",
      " dropout (Dropout)                     (None, 101, 300)           0             ['words_Embedding[0][0]']               \n",
      "                                                                                                                        \n",
      " conv1d (Conv1D)                       (None, 101, 256)           230656        ['dropout[0][0]']                       \n",
      "                                                                                                                        \n",
      " dropout_1 (Dropout)                   (None, 101, 256)           0             ['conv1d[0][0]']                        \n",
      "                                                                                                                        \n",
      " bidirectional (Bidirectional)         (None, 101, 128)           123648        ['dropout_1[0][0]']                     \n",
      "                                                                                                                        \n",
      " activation (Activation)               (None, 101, 128)           0             ['bidirectional[0][0]']                 \n",
      "                                                                                                                        \n",
      " dense (Dense)                         (None, 101, 1)             129           ['activation[0][0]']                    \n",
      "                                                                                                                        \n",
      " permute (Permute)                     (None, 1, 101)             0             ['dense[0][0]']                         \n",
      "                                                                                                                        \n",
      " attn_softmax (Activation)             (None, 1, 101)             0             ['permute[0][0]']                       \n",
      "                                                                                                                        \n",
      " words_input_mask (InputLayer)         [(None, 101)]              0             []                                      \n",
      "                                                                                                                        \n",
      " lambda (Lambda)                       (None, 1, 128)             0             ['attn_softmax[0][0]',                  \n",
      "                                                                                 'activation[0][0]']                    \n",
      "                                                                                                                        \n",
      " global_max_pooling1d (GlobalMaxPoolin  (None, 128)               0             ['activation[0][0]']                    \n",
      " g1D)                                                                                                                   \n",
      "                                                                                                                        \n",
      " mask_max_pooling_layer (MaskMaxPoolin  (None, 128)               0             ['activation[0][0]',                    \n",
      " gLayer)                                                                         'words_input_mask[0][0]']              \n",
      "                                                                                                                        \n",
      " flatten (Flatten)                     (None, 128)                0             ['lambda[0][0]']                        \n",
      "                                                                                                                        \n",
      " concatenate (Concatenate)             (None, 384)                0             ['global_max_pooling1d[0][0]',          \n",
      "                                                                                 'mask_max_pooling_layer[0][0]',        \n",
      "                                                                                 'flatten[0][0]']                       \n",
      "                                                                                                                        \n",
      " dropout_2 (Dropout)                   (None, 384)                0             ['concatenate[0][0]']                   \n",
      "                                                                                                                        \n",
      " dense_1 (Dense)                       (None, 300)                115500        ['dropout_2[0][0]']                     \n",
      "                                                                                                                        \n",
      " dense_2 (Dense)                       (None, 19)                 5719          ['dense_1[0][0]']                       \n",
      "                                                                                                                        \n",
      " activation_1 (Activation)             (None, 19)                 0             ['dense_2[0][0]']                       \n",
      "                                                                                                                        \n",
      "========================================================================================================================\n",
      "Total params: 7,510,652\n",
      "Trainable params: 7,510,652\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "words_input = Input(shape=(max_sentence_len,), dtype='int32', name='words_input')\n",
    "words_input_mask = Input(shape=(max_sentence_len,), dtype='int32', name='words_input_mask')\n",
    "\n",
    "words = Embedding(embedding.shape[0], embedding.shape[1], weights=[embedding], trainable=True, embeddings_regularizer=embeddings_reg, name=\"words_Embedding\")(words_input)\n",
    "words = Dropout(dropout_emb)(words)\n",
    "\n",
    "output = Convolution1D(filters=256, kernel_size=3, activation=activation_fn, padding='same', strides=1, kernel_regularizer=kernel_reg)(words)\n",
    "output = Dropout(dropout_model)(output)\n",
    "\n",
    "output = Bidirectional( CuDNNGRU(units, return_sequences=True, recurrent_regularizer=recurrent_reg), merge_mode='concat') (output)\n",
    "output_h = Activation('tanh') (output)\n",
    "\n",
    "output1 = GlobalMaxPooling1D()(output_h) \n",
    "output2 = MaskMaxPoolingLayer()([output_h, words_input_mask]) \n",
    "\n",
    "output = Dense(1, kernel_regularizer=kernel_reg)(output_h)\n",
    "output = Permute((2, 1))(output)\n",
    "output = Activation('softmax', name=\"attn_softmax\")(output)\n",
    "output = Lambda(lambda x: tf.matmul(x[0], x[1])) ([output, output_h])\n",
    "output3 = Flatten() (output)\n",
    "\n",
    "output = Concatenate()([output1, output2, output3])\n",
    "output = Dropout(dropout_pen)(output)\n",
    "\n",
    "output = Dense(300, kernel_regularizer=kernel_reg, activation='relu')(output)\n",
    "output = Dense(n_out, kernel_regularizer=kernel_reg)(output)\n",
    "output = Activation('softmax')(output)\n",
    "\n",
    "model = Model(inputs=[words_input, words_input_mask], outputs=[output])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=adadelta, metrics=['accuracy'])\n",
    "model.summary(line_length=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1654540242719,
     "user": {
      "displayName": "Gaganjot Shan",
      "userId": "18300755219130239353"
     },
     "user_tz": -120
    },
    "id": "EX-3X7w-Km9D"
   },
   "outputs": [],
   "source": [
    "# Evaluation functions \n",
    "\n",
    "def get_precision(test_y_pred, test_y, label): \n",
    "    label_count = 0\n",
    "    label_count_correct = 0\n",
    "    \n",
    "    for i in range(len(test_y_pred)):\n",
    "        if test_y_pred[i] == label: \n",
    "            label_count += 1 \n",
    "            if test_y_pred[i] == test_y[i]: \n",
    "                label_count_correct += 1\n",
    "    \n",
    "    if label_count_correct == 0: \n",
    "        return 0.0\n",
    "    else: \n",
    "        ret = float(label_count_correct) / float(label_count)\n",
    "        return ret\n",
    "        \n",
    "\n",
    "def get_macro_f1(test_y_pred, test_y, n_out):\n",
    "    f1_sum = 0\n",
    "    f1_count = 0\n",
    "    for label in range(1, n_out):        \n",
    "        prec = get_precision(test_y_pred, test_y, label)\n",
    "        recall = get_precision(test_y, test_y_pred, label)\n",
    "        f1 = 0 if float(prec+recall)==float(0) else float(2*prec*recall/float(prec+recall))\n",
    "        f1_sum += f1\n",
    "        f1_count += 1\n",
    "    macro_f1 = float(f1_sum) / float(f1_count)    \n",
    "    return macro_f1\n",
    "    \n",
    "\n",
    "def get_accuracy(test_y_pred, test_y):\n",
    "    acc =  float(np.sum(test_y_pred == test_y)) / float(len(test_y))\n",
    "    return acc\n",
    "    \n",
    "    \n",
    "def predict_classes(prediction):\n",
    "    return prediction.argmax(axis=-1)\n",
    "\n",
    "\n",
    "def get_PRF1_semeval(y_pred, answer_key):\n",
    "    \n",
    "    f_out = open(proposed_ans, 'w')\n",
    "    for i in range(len(y_pred)):\n",
    "        f_out.write(str(i+1) + \"\\t\" + int_to_label[y_pred[i]] + \"\\n\" )\n",
    "    f_out.close()\n",
    "    \n",
    "    if os.name == 'nt': \n",
    "        os.system(perl_exe_path + \" \" + scorer_perl_script + \" \" + proposed_ans + \" \" + answer_key + \" > \" + scorer_output)\n",
    "    else: \n",
    "        os.system(\"perl \" + \" \" + scorer_perl_script + \" \" + proposed_ans + \" \" + answer_key + \" > \" + scorer_output)\n",
    "        \n",
    "    f_in = open(scorer_output, 'r')\n",
    "    lines = f_in.readlines()\n",
    "    f_in.close()\n",
    "    \n",
    "    lines = [ l  for l in lines[-30:] if l.strip() != '']\n",
    "        \n",
    "    acc = float(lines[-17].strip().split()[-1][:-1]) / 100.0\n",
    "    PRF1 = lines[-2].strip().split()\n",
    "    P = float(PRF1[2][:-1]) / 100.0\n",
    "    R = float(PRF1[5][:-1]) / 100.0\n",
    "    macro_f1 = float(PRF1[8][:-1]) / 100.0\n",
    "    \n",
    "    return (acc, P, R, macro_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "executionInfo": {
     "elapsed": 4469,
     "status": "error",
     "timestamp": 1654540247185,
     "user": {
      "displayName": "Gaganjot Shan",
      "userId": "18300755219130239353"
     },
     "user_tz": -120
    },
    "id": "wjHYqqI7K3yq",
    "outputId": "0447e7c5-7a5e-49ee-e6e9-17df91cc28f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training... \n",
      "\n",
      "Epoch:  1 / 256\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f65f3c26290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f65f3c26290> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a84965410ca6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mtrain_y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input_list_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNNV2' used by {{node model/bidirectional/forward_cu_dnngru/CudnnRNNV2}} with these attrs: [dropout=0, seed=0, input_mode=\"linear_input\", T=DT_FLOAT, direction=\"unidirectional\", rnn_mode=\"gru\", seed2=0, is_training=true]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[model/bidirectional/forward_cu_dnngru/CudnnRNNV2]] [Op:__inference_train_function_2919]"
     ]
    }
   ],
   "source": [
    "print(\"Start training... \\n\")\n",
    "\n",
    "# train_x = train_x[:200]\n",
    "# train_y = train_y[:200]\n",
    "# train_x_copy = train_x_copy[:200]\n",
    "# train_y_copy = train_y_copy[:200]\n",
    "# val_x = val_x[:200]\n",
    "# val_y = val_y[:200]\n",
    "# test_x = test_x[:200]\n",
    "# test_y = test_y[:200]\n",
    "\n",
    "\n",
    "train_max_acc = 0\n",
    "train_max_f1 = 0\n",
    "val_max_acc = 0\n",
    "val_max_f1 = 0\n",
    "test_max_acc = 0\n",
    "test_max_f1 = 0\n",
    "\n",
    "test_f1_final = 0\n",
    "test_f1_final_max = 0\n",
    "\n",
    "es_epoch = 0 \n",
    "\n",
    "for epoch in range(nb_epoch):\n",
    "    print(\"Epoch: \", epoch+1, \"/\", nb_epoch)\n",
    "    es_epoch += 1\n",
    "    if es_epoch > es_epoch_stop:\n",
    "        print(\"Early Stopping...\") \n",
    "        break\n",
    "    \n",
    "    index = np.arange(len(train_x))\n",
    "    np.random.shuffle(index)\n",
    "    train_x = train_x[index]\n",
    "    train_x_mask = train_x_mask[index]\n",
    "    train_y = train_y[index]\n",
    "    \n",
    "    # Input lists for fit and predict\n",
    "    #\n",
    "    train_input_list = [train_x, train_x_mask]\n",
    "    train_input_list_copy = [train_x_copy, train_x_mask_copy]\n",
    "    val_input_list = [val_x, val_x_mask]\n",
    "    test_input_list = [test_x, test_x_mask]\n",
    "    #train_input_list = [train_x]\n",
    "    #train_input_list_copy = [train_x_copy]\n",
    "    #val_input_list = [val_x]\n",
    "    #test_input_list = [test_x]\n",
    "\n",
    "    \n",
    "    model.fit(train_input_list, train_y, batch_size=batch_size, verbose=1, epochs=1) \n",
    "    \n",
    "    train_y_pred = predict_classes(model.predict(train_input_list_copy, verbose=1))\n",
    "    val_y_pred = predict_classes(model.predict(val_input_list, verbose=1))\n",
    "    test_y_pred = predict_classes(model.predict(test_input_list, verbose=1))\n",
    "    \n",
    "    train_PRF1 = get_PRF1_semeval(train_y_pred, train_answer_key)\n",
    "    val_PRF1 = get_PRF1_semeval(val_y_pred, val_answer_key)\n",
    "    test_PRF1 = get_PRF1_semeval(test_y_pred, test_answer_key)\n",
    "\n",
    "    train_max_f1 = max(train_max_f1, train_PRF1[3])\n",
    "    val_max_f1 = max(val_max_f1, val_PRF1[3])\n",
    "    test_max_f1 = max(test_max_f1, test_PRF1[3])\n",
    "\n",
    "    train_max_acc = max(train_max_acc, train_PRF1[0])\n",
    "    val_max_acc = max(val_max_acc, val_PRF1[0])\n",
    "    test_max_acc = max(test_max_acc, test_PRF1[0])\n",
    "    \n",
    "    if val_max_f1 == val_PRF1[3]: \n",
    "        test_f1_final = test_PRF1[3]\n",
    "        test_f1_final_max = max(test_f1_final, test_f1_final_max)\n",
    "        if save_model : \n",
    "            model_file_name = \"model.keras\"\n",
    "            model.save('./model/' + model_file_name)\n",
    "            print(\"Model saved\", model_file_name)\n",
    "        es_epoch = 0\n",
    "    \n",
    "    print(\"Train Accuracy: %.4f (max: %.4f)\" % (train_PRF1[0], train_max_acc))\n",
    "    print(\"Val   Accuracy: %.4f (max: %.4f)\" % (val_PRF1[0], val_max_acc))\n",
    "    print(\"Test  Accuracy: %.4f (max: %.4f)\" % (test_PRF1[0], test_max_acc))\n",
    "    \n",
    "    print(\"Train Macro F1 Semeval Official: %.4f (max: %.4f)\" % (train_PRF1[3], train_max_f1))\n",
    "    print(\"Val   Macro F1 Semeval Official: %.4f (max: %.4f)\" % (val_PRF1[3], val_max_f1))\n",
    "    print(\"Test  Macro F1 Semeval Official: %.4f (max: %.4f)\" % (test_PRF1[3], test_max_f1))\n",
    "    print(\"Test P %.4f | R %.4f | macro_F1: %.4f\" % test_PRF1[1:] )\n",
    "    print(\"Test test_max_f1_final: %.4f (max: %.4f)\" % (test_f1_final, test_f1_final_max) )\n",
    "        \n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Neural_Rel_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
